{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzZbP0LM6m5z"
      },
      "source": [
        "# Extractive QA with Elasticsearch\n",
        "\n",
        "_This notebook is part of a tutorial series on [txtai](https://github.com/neuml/txtai), an AI-powered semantic search platform._\n",
        "\n",
        "txtai is datastore agnostic, the library analyzes sets of text. The following example shows how extractive question-answering can be added on top of an Elasticsearch system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk7t5Jcd6reO"
      },
      "source": [
        "# Install dependencies\n",
        "\n",
        "Install `txtai` and `Elasticsearch`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0y1UA4-q-YdA"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Install txtai and elasticsearch python client\n",
        "!pip install git+https://github.com/neuml/txtai elasticsearch\n",
        "\n",
        "# Download and extract elasticsearch\n",
        "!wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.4.2-linux-x86_64.tar.gz\n",
        "!tar -xzf elasticsearch-8.4.2-linux-x86_64.tar.gz\n",
        "!chown -R daemon:daemon elasticsearch-8.4.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKWz-C5gCJy8"
      },
      "source": [
        "Start an instance of Elasticsearch directly within this notebook. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZfJeWbM6wmj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "\n",
        "# If issues are encountered with this section, ES can be manually started as follows:\n",
        "# ./elasticsearch-8.4.2/bin/elasticsearch\n",
        "\n",
        "# Start and wait for server\n",
        "server = Popen(['elasticsearch-8.4.2/bin/elasticsearch'], stdout=PIPE, stderr=STDOUT, preexec_fn=lambda: os.setuid(1))\n",
        "!sleep 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWEn4w68-D1y"
      },
      "source": [
        "# Download data\n",
        "\n",
        "This example is going to work off a subset of the [CORD-19](https://www.semanticscholar.org/cord19) dataset. COVID-19 Open Research Dataset (CORD-19) is a free resource of scholarly articles, aggregated by a coalition of leading research groups, covering COVID-19 and the coronavirus family of viruses.\n",
        "\n",
        "The following download is a SQLite database generated from a [Kaggle notebook](https://www.kaggle.com/davidmezzetti/cord-19-slim/output). More information on this data format, can be found in the [CORD-19 Analysis](https://www.kaggle.com/davidmezzetti/cord-19-analysis-with-sentence-embeddings) notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tVrIqSq-KBa"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget https://github.com/neuml/txtai/releases/download/v1.1.0/tests.gz\n",
        "!gunzip tests.gz\n",
        "!mv tests covid.sqlite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSWFzkCn61tM"
      },
      "source": [
        "# Load data into Elasticsearch\n",
        "\n",
        "The following block copies rows from SQLite to Elasticsearch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So-OBvUT61QD",
        "outputId": "9647b8f8-8471-41bf-ccfa-a75306665638"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nick/tmp/ipykernel_27180/3000853871.py:8: DeprecationWarning: The 'timeout' parameter is deprecated in favor of 'request_timeout'\n",
            "  es = Elasticsearch(hosts=[\"http://localhost:9200\"], timeout=60, retry_on_timeout=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total articles inserted: 21499\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "\n",
        "import regex as re\n",
        "\n",
        "from elasticsearch import Elasticsearch, helpers\n",
        "\n",
        "# Connect to ES instance\n",
        "es = Elasticsearch(hosts=[\"http://localhost:9200\"], timeout=60, retry_on_timeout=True)\n",
        "\n",
        "# Connection to database file\n",
        "db = sqlite3.connect(\"covid.sqlite\")\n",
        "cur = db.cursor()\n",
        "\n",
        "# Elasticsearch bulk buffer\n",
        "buffer = []\n",
        "rows = 0\n",
        "\n",
        "# Select tagged sentences without a NLP label. NLP labels are set for non-informative sentences.\n",
        "cur.execute(\"SELECT s.Id, Article, Title, Published, Reference, Name, Text FROM sections s JOIN articles a on s.article=a.id WHERE (s.labels is null or s.labels NOT IN ('FRAGMENT', 'QUESTION')) AND s.tags is not null\")\n",
        "for row in cur:\n",
        "  # Build dict of name-value pairs for fields\n",
        "  article = dict(zip((\"id\", \"article\", \"title\", \"published\", \"reference\", \"name\", \"text\"), row))\n",
        "  name = article[\"name\"]\n",
        "\n",
        "  # Only process certain document sections\n",
        "  if not name or not re.search(r\"background|(?<!.*?results.*?)discussion|introduction|reference\", name.lower()):\n",
        "    # Bulk action fields\n",
        "    article[\"_id\"] = article[\"id\"]\n",
        "    article[\"_index\"] = \"covid\"\n",
        "\n",
        "    # Buffer article\n",
        "    buffer.append(article)\n",
        "\n",
        "    # Increment number of articles processed\n",
        "    rows += 1\n",
        "\n",
        "    # Bulk load every 1000 records\n",
        "    if rows % 1000 == 0:\n",
        "      helpers.bulk(es, buffer)\n",
        "      buffer = []\n",
        "\n",
        "      print(\"Inserted {} articles\".format(rows), end=\"\\r\")\n",
        "\n",
        "if buffer:\n",
        "  helpers.bulk(es, buffer)\n",
        "\n",
        "print(\"Total articles inserted: {}\".format(rows))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5RO-VNwzMAo"
      },
      "source": [
        "# Query data\n",
        "\n",
        "The following runs a query against Elasticsearch for the terms \"risk factors\". It finds the top 5 matches and returns the corresponding documents associated with each match.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "ucd9mwSfFTMm",
        "outputId": "b21d6aff-6abe-48f5-9914-7b7fb8472adb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Title</th>\n",
              "      <th>Published</th>\n",
              "      <th>Reference</th>\n",
              "      <th>Match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>Management of osteoarthritis during COVID‐19 pandemic</td>\n",
              "      <td>2020-05-21 00:00:00</td>\n",
              "      <td>https://doi.org/10.1002/cpt.1910</td>\n",
              "      <td>Indeed, risk factors are sex, obesity, genetic factors and mechanical factors (3) .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Prevalence and Impact of Myocardial Injury in Patients Hospitalized with COVID-19 Infection</td>\n",
              "      <td>2020-04-24 00:00:00</td>\n",
              "      <td>http://medrxiv.org/cgi/content/short/2020.04.20.20072702v1?rss=1</td>\n",
              "      <td>This risk was consistent across patients stratified by history of CVD, risk factors but no CVD, and neither CVD nor risk factors.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Does apolipoprotein E genotype predict COVID-19 severity?</td>\n",
              "      <td>2020-04-27 00:00:00</td>\n",
              "      <td>https://doi.org/10.1093/qjmed/hcaa142</td>\n",
              "      <td>Risk factors associated with subsequent death include older age, hypertension, diabetes, ischemic heart disease, obesity and chronic lung disease; however, sometimes there are no obvious risk factors .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>COVID-19 and associations with frailty and multimorbidity: a prospective analysis of UK Biobank participants</td>\n",
              "      <td>2020-07-23 00:00:00</td>\n",
              "      <td>https://www.ncbi.nlm.nih.gov/pubmed/32705587/</td>\n",
              "      <td>BACKGROUND: Frailty and multimorbidity have been suggested as risk factors for severe COVID-19 disease.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>COVID-19: what has been learned and to be learned about the novel coronavirus disease</td>\n",
              "      <td>2020-03-15 00:00:00</td>\n",
              "      <td>https://doi.org/10.7150/ijbs.45134</td>\n",
              "      <td>• Three major risk factors for COVID-19 were sex (male), age (≥60), and severe pneumonia.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "\n",
        "source=[\"article\", \"title\", \"published\", \"reference\", \"text\"]\n",
        "size = 5\n",
        "query = {\n",
        "  \"query_string\": {\"query\": \"risk factors\"}\n",
        "}\n",
        "\n",
        "results = []\n",
        "for result in es.search(index=\"covid\", query=query, source=source, size=size)[\"hits\"][\"hits\"]:\n",
        "  source = result[\"_source\"]\n",
        "  results.append((source[\"title\"], source[\"published\"], source[\"reference\"], source[\"text\"]))\n",
        "\n",
        "df = pd.DataFrame(results, columns=[\"Title\", \"Published\", \"Reference\", \"Match\"])\n",
        "\n",
        "display(HTML(df.to_html(index=False)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylxOKji1-9_K"
      },
      "source": [
        "# Derive columns with Extractive QA\n",
        "\n",
        "The next section uses Extractive QA to derive additional columns. For each article, the full text is retrieved and a series of questions are asked of the document. The answers are added as a derived column per article."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mwBTrCkcOM_H"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from txtai.embeddings import Embeddings\n",
        "from txtai.pipeline import Extractor\n",
        "\n",
        "# Create embeddings model, backed by sentence-transformers & transformers\n",
        "embeddings = Embeddings({\"path\": \"sentence-transformers/nli-mpnet-base-v2\"})\n",
        "\n",
        "# Create extractor instance using qa model designed for the CORD-19 dataset\n",
        "extractor = Extractor(embeddings, \"NeuML/bert-small-cord19qa\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "Yv75Lh-cOpL9",
        "outputId": "adee88e1-02bf-4a20-febb-6d2c170a63f9"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "tuple indices must be integers or slices, not str",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [25], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m   source \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     28\u001b[0m   \u001b[38;5;66;03m# Use QA extractor to derive additional columns\u001b[39;00m\n\u001b[1;32m     29\u001b[0m   answers \u001b[38;5;241m=\u001b[39m extractor([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRisk factors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrisk factor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are names of risk factors?\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m---> 30\u001b[0m                        (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocations\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcity country state\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are names of locations?\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)], sections(source[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticle\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m     32\u001b[0m   results\u001b[38;5;241m.\u001b[39mappend((source[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m], source[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpublished\u001b[39m\u001b[38;5;124m\"\u001b[39m], source[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreference\u001b[39m\u001b[38;5;124m\"\u001b[39m], source[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m([answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m answer \u001b[38;5;129;01min\u001b[39;00m answers]))\n\u001b[1;32m     34\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPublished\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReference\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRisk Factors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocations\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
            "Cell \u001b[0;32mIn [25], line 13\u001b[0m, in \u001b[0;36msections\u001b[0;34m(article)\u001b[0m\n\u001b[1;32m     10\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#search = document.copy()\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mquery2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mterm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticle\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m article\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m es\u001b[38;5;241m.\u001b[39msearch(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcovid\u001b[39m\u001b[38;5;124m\"\u001b[39m, source\u001b[38;5;241m=\u001b[39msource, size\u001b[38;5;241m=\u001b[39msize, query\u001b[38;5;241m=\u001b[39mquery2, sort\u001b[38;5;241m=\u001b[39msort)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     16\u001b[0m   source \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
          ]
        }
      ],
      "source": [
        "source = [\"id\", \"name\", \"text\"]\n",
        "size = 1000,\n",
        "query = {\n",
        "    \"term\": {\"article\": None}\n",
        "},\n",
        "sort= [\"id\"]\n",
        "\n",
        "\n",
        "def sections(article):\n",
        "  rows = []\n",
        "\n",
        "  #search = document.copy()\n",
        "  query[\"term\"][\"article\"] = article\n",
        "\n",
        "  for result in es.search(index=\"covid\", source=source, size=size, query=query, sort=sort)[\"hits\"][\"hits\"]:\n",
        "    source = result[\"_source\"]\n",
        "    name, text = source[\"name\"], source[\"text\"]\n",
        "\n",
        "    if not name or not re.search(r\"background|(?<!.*?results.*?)discussion|introduction|reference\", name.lower()):\n",
        "      rows.append(text)\n",
        "  \n",
        "  return rows\n",
        "\n",
        "results = []\n",
        "for result in es.search(index=\"covid\", query=query)[\"hits\"][\"hits\"]:\n",
        "  source = result[\"_source\"]\n",
        "\n",
        "  # Use QA extractor to derive additional columns\n",
        "  answers = extractor([(\"Risk factors\", \"risk factor\", \"What are names of risk factors?\", False),\n",
        "                       (\"Locations\", \"city country state\", \"What are names of locations?\", False)], sections(source[\"article\"]))\n",
        "\n",
        "  results.append((source[\"title\"], source[\"published\"], source[\"reference\"], source[\"text\"]) + tuple([answer[1] for answer in answers]))\n",
        "\n",
        "df = pd.DataFrame(results, columns=[\"Title\", \"Published\", \"Reference\", \"Match\", \"Risk Factors\", \"Locations\"])\n",
        "\n",
        "display(HTML(df.to_html(index=False)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "06 - Extractive QA with Elasticsearch",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "a0c80364a31303592ff70a2b59e729e9530c4527b4f2818eee18c2b86336382d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
