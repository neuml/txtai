{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzZbP0LM6m5z"
      },
      "source": [
        "# Add semantic search to Elasticsearch\n",
        "\n",
        "_This notebook is part of a tutorial series on [txtai](https://github.com/neuml/txtai), an AI-powered semantic search platform._\n",
        "\n",
        "Part 2 and Part 3 of this series showed how to index and search data in txtai. Part 2 indexed and searched a Hugging Face Dataset, Part 3 indexed and searched an external data source. \n",
        "\n",
        "txtai is modular in design, it's components can be individually used. txtai has a similarity function that works on lists of text. This method can be integrated with any external search service, such as a REST API, a SQL query or anything else that returns text search results. \n",
        "\n",
        "In this notebook, we'll take the same Hugging Face Dataset used in Part 2, index it in Elasticsearch and rank the search results using a semantic similarity function from txtai.\n",
        "\n",
        "**Make sure to select a GPU runtime when running this notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk7t5Jcd6reO"
      },
      "source": [
        "# Install dependencies\n",
        "\n",
        "Install `txtai`, `datasets` and `Elasticsearch`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0y1UA4-q-YdA"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Install txtai, datasets and elasticsearch python client\n",
        "!pip install git+https://github.com/neuml/txtai datasets elasticsearch\n",
        "\n",
        "# Download and extract elasticsearch\n",
        "!wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.4.2-linux-x86_64.tar.gz\n",
        "!tar -xzf elasticsearch-8.4.2-linux-x86_64.tar.gz\n",
        "!chown -R daemon:daemon elasticsearch-8.4.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5c_WxmxCShQ"
      },
      "source": [
        "Start an instance of Elasticsearch directly within this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZfJeWbM6wmj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "\n",
        "# If issues are encountered with this section, ES can be manually started as follows:\n",
        "# ./elasticsearch-8.4.2/bin/elasticsearch\n",
        "\n",
        "# Start and wait for server\n",
        "server = Popen(['elasticsearch-8.4.2/bin/elasticsearch'], stdout=PIPE, stderr=STDOUT, preexec_fn=lambda: os.setuid(1))\n",
        "!sleep 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSWFzkCn61tM"
      },
      "source": [
        "# Load data into Elasticsearch\n",
        "\n",
        "The following block loads the dataset into Elasticsearch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So-OBvUT61QD"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "from elasticsearch import Elasticsearch, helpers\n",
        "\n",
        "# Connect to ES instance\n",
        "es = Elasticsearch(hosts=[\"http://localhost:9200\"], timeout=60, retry_on_timeout=True)\n",
        "\n",
        "# Load HF dataset\n",
        "dataset = load_dataset(\"ag_news\", split=\"train\")[\"text\"][:50000]\n",
        "\n",
        "# Elasticsearch bulk buffer\n",
        "buffer = []\n",
        "rows = 0\n",
        "\n",
        "for x, text in enumerate(dataset):\n",
        "  # Article record\n",
        "  article = {\"_id\": x, \"_index\": \"ag_news\", \"title\": text}\n",
        "\n",
        "  # Buffer article\n",
        "  buffer.append(article)\n",
        "\n",
        "  # Increment number of articles processed\n",
        "  rows += 1\n",
        "\n",
        "  # Bulk load every 1000 records\n",
        "  if rows % 1000 == 0:\n",
        "    helpers.bulk(es, buffer)\n",
        "    buffer = []\n",
        "\n",
        "    print(\"Inserted {} articles\".format(rows), end=\"\\r\")\n",
        "\n",
        "if buffer:\n",
        "  helpers.bulk(es, buffer)\n",
        "\n",
        "print(\"Total articles inserted: {}\".format(rows))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5RO-VNwzMAo"
      },
      "source": [
        "# Query data with Elasticsearch\n",
        "\n",
        "Elasticsearch is a token-based search system. Queries and documents are parsed into tokens and the most relevant query-document matches are calculated using a scoring algorithm. The default scoring algorithm is [BM25](https://www.elastic.co/blog/practical-bm25-part-2-the-bm25-algorithm-and-its-variables). Powerful queries can be built using a [rich query syntax](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html#query-string-syntax) and [Query DSL](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/query-dsl.html). \n",
        "\n",
        "The following section runs a query against Elasticsearch, finds the top 5 matches and returns the corresponding documents associated with each match.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "ucd9mwSfFTMm",
        "outputId": "1c49323e-1f29-491d-872a-14b5650d09f6"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "def table(category, query, rows):\n",
        "    html = \"\"\"\n",
        "    <style type='text/css'>\n",
        "    @import url('https://fonts.googleapis.com/css?family=Oswald&display=swap');\n",
        "    table {\n",
        "      border-collapse: collapse;\n",
        "      width: 900px;\n",
        "    }\n",
        "    th, td {\n",
        "        border: 1px solid #9e9e9e;\n",
        "        padding: 10px;\n",
        "        font: 15px Oswald;\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\"\n",
        "\n",
        "    html += \"<h3>[%s] %s</h3><table><thead><tr><th>Score</th><th>Text</th></tr></thead>\" % (category, query)\n",
        "    for score, text in rows:\n",
        "        html += \"<tr><td>%.4f</td><td>%s</td></tr>\" % (score, text)\n",
        "    html += \"</table>\"\n",
        "\n",
        "    display(HTML(html))\n",
        "\n",
        "def search(query, limit):\n",
        "  query = {\n",
        "    \"query_string\": {\"query\": query}\n",
        "  }\n",
        "  size = limit\n",
        "  \n",
        "  results = []\n",
        "  for result in es.search(index=\"ag_news\", query=query, size=size)[\"hits\"][\"hits\"]:\n",
        "    source = result[\"_source\"]\n",
        "    results.append((min(result[\"_score\"], 18) / 18, source[\"title\"]))\n",
        "\n",
        "  return results\n",
        "\n",
        "limit = 3\n",
        "query= \"+yankees lose\"\n",
        "table(\"Elasticsearch\", query, search(query, limit))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1DkpcIob5kt"
      },
      "source": [
        "The table above shows the results for the query `+yankees lose`. This query requires the token `yankees`. The search doesn't understand the semantic meaning of the query. It returns the most relevant results with those two tokens.\n",
        "\n",
        "We can see in this case, the results aren't capturing the meaning of the search. Let's try adding semantic similarity to the search!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMro47KedzJq"
      },
      "source": [
        "# Ranking search results with txtai\n",
        "\n",
        "txtai has a similarity module that computes the similarity between a query and a list of strings. Of course, txtai can also build a full index as shown in the previous notebooks but in this case we'll just use the ad-hoc similarity function.\n",
        "\n",
        "The code below creates a Similarity instance and defines a ranking function to order search results based on the computed similarity.\n",
        "\n",
        "`ranksearch` queries Elasticsearch for a larger set of results, ranks the results using the similarity instance and returns the top n results. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUOj5zhFFK8N"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from txtai.pipeline import Similarity\n",
        "\n",
        "def ranksearch(query, limit):\n",
        "  results = [text for _, text in search(query, limit * 10)]\n",
        "  return [(score, results[x]) for x, score in similarity(query, results)][:limit]\n",
        "\n",
        "# Create similarity instance for re-ranking\n",
        "similarity = Similarity(\"valhalla/distilbart-mnli-12-3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMFuv5-Hedfc"
      },
      "source": [
        "Now let's re-run the previous search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "3jJI9OxU0dZk",
        "outputId": "3233d128-2bf4-4d53-f851-f9dd8f51629e"
      },
      "outputs": [],
      "source": [
        "# Run the search\n",
        "table(\"Elasticsearch + txtai\", query, ranksearch(query, limit))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXB2PaDZfd8o"
      },
      "source": [
        "The results above do a much better job of finding results semantically similar in meaning to the query. Instead of just finding matches with `yankees` and `lose`, it finds matches where the `yankees lose`. \n",
        "\n",
        "This combination is effective and powerful. It takes advantage of the high performance of Elasticsearch while adding a semantic search capability. We may already have a large Elasticsearch cluster with TBs (or PBs)+ of data and years of engineering investment that solves most use cases. Semantically ranking search results is a practical approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBVL56fsRI86"
      },
      "source": [
        "# More examples\n",
        "\n",
        "Now for some more examples comparing the results from Elasticsearch vs Elasticsearch + txtai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7IHS38SERRpQ",
        "outputId": "25325d94-ddc9-44f2-f602-d792ffeb0a8c"
      },
      "outputs": [],
      "source": [
        "for query in [\"good news +economy\", \"bad news +economy\"]:\n",
        "  table(\"Elasticsearch\", query, search(query, limit))\n",
        "  table(\"Elasticsearch + txtai\", query, ranksearch(query, limit))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-Bk3KLjZMpF"
      },
      "source": [
        "Once again while Elasticsearch usually returns quality results, occasionally it will match results that aren't semantically relevant. The power of semantic search is that not only will it find direct matches but matches with the same meaning.  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "04 - Add semantic search to Elasticsearch",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "a0c80364a31303592ff70a2b59e729e9530c4527b4f2818eee18c2b86336382d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
